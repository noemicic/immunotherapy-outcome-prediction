{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba87a27",
   "metadata": {},
   "source": [
    "# PFS: classical ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc076108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#Importing libraries for preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Importing libraries for models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "#Importing libraries for evaluation\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "#Importing library for interpretability\n",
    "import shap\n",
    "#For reproducibility\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('dataset_b.csv', encoding='latin-1', sep=',') # request the dataset to the author\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column : \"pfsduree_immunoth\", continuous variable\n",
    "# relevant columns\n",
    "relevant_columns = ['age', 'dcr', 'dnlr', 'histology', 'immuno_line', 'iorr', \n",
    "                    'ldhpre', 'leucotpre', 'nb_meta_beforeimmuno', 'neuttpre', \n",
    "                     'ps_befimmuno', 'sex', 'smoking_history', 'pfsduree_immunoth']\n",
    "\n",
    "data = data[relevant_columns]\n",
    "data = data.dropna(axis=0)\n",
    "data['dcr'] = data['dcr'].astype(int)\n",
    "data['age'] = data['age'].astype(int)\n",
    "data['iorr'] = data['iorr'].astype(int)\n",
    "data['ps_befimmuno'] = data['ps_befimmuno'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd423006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"encode\" the categorical variables\n",
    "data['histology'] = data['histology'].str.lower()\n",
    "data['sex'] = data['sex'].str.lower()\n",
    "data['smoking_history'] = data['smoking_history'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c72891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to randomize the data\n",
    "data = data.sample(frac=1, random_state=SEED)\n",
    "\n",
    "# one-hot encoding\n",
    "one_hot_data = pd.get_dummies(data, columns=['histology', 'sex', 'smoking_history'])\n",
    "\n",
    "one_hot_data = one_hot_data.rename(columns={\n",
    "    'histology_Adenocarcinoma': 'histology_adenocarcinoma',\n",
    "    'histology_Squamous': 'histology_squamous',\n",
    "    'histology_Nsclc_other': 'histology_nsclc_other',\n",
    "    'histology_Large_cells': 'histology_large_cells',\n",
    "    'sex_Male': 'sex_male',\n",
    "    'sex_Female': 'sex_female',\n",
    "    'smoking_history_Non_smoker': 'smoking_history_non_smoker',\n",
    "    'smoking_history_Former': 'smoking_history_former',\n",
    "    'smoking_history_Current': 'smoking_history_current',\n",
    "    'smoking_history_Unk': 'smoking_history_unk'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1677b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace boolean values with 0 and 1\n",
    "for col in ['histology_adenocarcinoma','histology_squamous','histology_nsclc other',\n",
    "    'histology_large cells','sex_male','sex_female','smoking_history_non smoker','smoking_history_former','smoking_history_current',\n",
    "     'smoking_history_unk']:\n",
    "    one_hot_data[col] = one_hot_data[col].replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target\n",
    "X = one_hot_data[one_hot_data.columns.difference(['pfsduree_immunoth'])]\n",
    "y = data['pfsduree_immunoth']\n",
    "\n",
    "# First division: training+val vs. test (80% vs. 20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42  \n",
    ")\n",
    "\n",
    "# Second division: training vs. validation (75% vs. 25% of the 80%)\n",
    "# This results in 60% training, 20% validation, 20% test   \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169cbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ensures that all numerical features contribute equally\n",
    "numerical_features = ['age', 'dcr', 'dnlr', 'ldhpre', 'leucotpre', \n",
    "                      'nb_meta_beforeimmuno', 'neuttpre', 'ps_befimmuno']\n",
    "\n",
    "binary_features = [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy() \n",
    "X_test_scaled = X_test.copy()\n",
    "X_scaled = X.copy()\n",
    "X_train_val_scaled = X_temp.copy()\n",
    "\n",
    "X_scaled[numerical_features] = scaler.fit_transform(X_scaled[numerical_features])\n",
    "X_train_scaled[numerical_features] = scaler.fit_transform(X_train_scaled[numerical_features])\n",
    "X_val_scaled[numerical_features] = scaler.transform(X_val_scaled[numerical_features])\n",
    "X_test_scaled[numerical_features] = scaler.transform(X_test_scaled[numerical_features])\n",
    "X_train_val_scaled[numerical_features] = scaler.fit_transform(X_train_val_scaled[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    denom = np.where(denom == 0, 1e-8, denom)  # to avoid division by zero\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom) * 100\n",
    "\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate a regression model with MSE, MAE, MAPE and sMAPE.\n",
    "\n",
    "    Parametri:\n",
    "        y_true: array-like, true values\n",
    "        y_pred: array-like, predicted values\n",
    "    \"\"\"\n",
    "\n",
    "    # Metric calculations\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "    print(f\"Symmetric Mean Absolute Percentage Error (sMAPE): {smape:.2f}%\")\n",
    "\n",
    "    # Plot: Predicted vs True\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_true.min(), y_true.max()],\n",
    "             [y_true.min(), y_true.max()],\n",
    "             'r--', label='Perfect Prediction')\n",
    "    plt.xlabel(\"True Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(f\"Predicted vs True \")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return {\"MSE\": mse, \"MAE\": mae, \"MAPE\": mape, \"sMAPE\": smape}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425deaf",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred, epsilon=1e-8):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = np.maximum(np.abs(y_true), epsilon)  # to avoid division by zero\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'neg_mse': 'neg_mean_squared_error',\n",
    "    'neg_mae': 'neg_mean_absolute_error',\n",
    "    'neg_mape': mape_scorer\n",
    "}\n",
    "\n",
    "param_grid_linear = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LinearRegression(),\n",
    "    param_grid=param_grid_linear,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "print(\"Best Linear params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db028c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_best = grid.best_estimator_\n",
    "\n",
    "lr_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "y_pred_lr_best = lr_model_best.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_scaled_df = pd.DataFrame(X_train_val_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7707c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(lr_model_best, X_train_val_scaled_df)\n",
    "\n",
    "shap_values = explainer(X_test_scaled_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features) + len(numerical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86770e",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ridge = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sag', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    Ridge(max_iter=10000, random_state=SEED),\n",
    "    param_grid=param_grid_ridge,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "print(\"Best Ridge params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model_best = grid.best_estimator_\n",
    "\n",
    "ridge_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "y_pred_lr_best = ridge_model_best.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bea859",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(ridge_model_best, X_train_val_scaled_df)\n",
    "\n",
    "shap_values = explainer(X_test_scaled_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features) + len(numerical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fecbf5",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lasso = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    Lasso(random_state=SEED),\n",
    "    param_grid=param_grid_lasso,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "print(\"Best Lasso params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ade0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_best = grid.best_estimator_\n",
    "\n",
    "lasso_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "y_pred_lr_best = lasso_model_best.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(lasso_model_best, X_train_val_scaled_df)\n",
    "\n",
    "shap_values = explainer(X_test_scaled_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features) + len(numerical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b56d9",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ff3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_elastic = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'l1_ratio': [0.1, 0.5, 0.7, 0.9, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    ElasticNet(random_state=SEED),\n",
    "    param_grid=param_grid_elastic,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "print(\"Best ElasticNet params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model_best = grid.best_estimator_\n",
    "\n",
    "elastic_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "y_pred_lr_best = elastic_model_best.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9258761",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(elastic_model_best, X_train_val_scaled_df)\n",
    "\n",
    "shap_values = explainer(X_test_scaled_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ba74e",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=SEED),\n",
    "    param_grid=param_grid_dt,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_temp, y_temp)\n",
    "print(\"Best Decision Tree params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f272e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_best = grid.best_estimator_\n",
    "\n",
    "dt_model_best.fit(X_temp, y_temp)\n",
    "\n",
    "y_pred_lr_best = dt_model_best.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06682c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_df = pd.DataFrame(X_temp, columns=X_temp.columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(dt_model_best, X_temp_df)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e328f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=SEED),\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_temp, y_temp)\n",
    "print(\"Best Random Forest params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_best = grid.best_estimator_\n",
    "\n",
    "rf_model_best.fit(X_temp, y_temp)\n",
    "\n",
    "y_pred_lr_best = rf_model_best.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac562edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_model_best, X_temp_df)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b88025",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e02a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=SEED),\n",
    "    param_grid=param_grid_gb,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_temp, y_temp)\n",
    "print(\"Best Gradient Boosting params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ffc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_best = grid.best_estimator_\n",
    "\n",
    "gb_model_best.fit(X_temp, y_temp)\n",
    "\n",
    "y_pred_lr_best = gb_model_best.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(gb_model_best, X_temp_df)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b202c5",
   "metadata": {},
   "source": [
    "# K-Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 = Manhattan, 2 = Euclidean\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    param_grid=param_grid_knn,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a29b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_best = grid.best_estimator_\n",
    "\n",
    "knn_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "y_pred_lr_best = knn_model_best.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_train_val_scaled_df.sample(100, random_state=SEED)\n",
    "\n",
    "explainer = shap.KernelExplainer(knn_model_best.predict, X_sample)\n",
    "\n",
    "X_test_sample = X_test_scaled_df.sample(50, random_state=SEED)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.summary_plot(shap_values, X_test_sample, feature_names=X_test_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c311dd2",
   "metadata": {},
   "source": [
    "# Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'epsilon': [0.01, 0.1, 1.0],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    SVR(),\n",
    "    param_grid=param_grid_svr,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "print(\"Best SVR params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model_best = grid.best_estimator_\n",
    "\n",
    "svr_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "y_pred_lr_best = svr_model_best.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(svr_model_best, X_train_val_scaled_df)\n",
    "\n",
    "shap_values = explainer(X_test_scaled_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bc875",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    xgb.XGBRegressor(random_state=SEED, verbosity=0),\n",
    "    param_grid=param_grid_xgb,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_temp, y_temp)\n",
    "print(\"Best XGB params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_best = grid.best_estimator_\n",
    "\n",
    "xgb_model_best.fit(X_temp, y_temp)\n",
    "\n",
    "y_pred_lr_best = xgb_model_best.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(xgb_model_best, X_temp_df)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e484eae",
   "metadata": {},
   "source": [
    "# LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64055d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [-1, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves': [31, 50]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LGBMRegressor(random_state=SEED),\n",
    "    param_grid=param_grid_lgb,\n",
    "    scoring=scoring,\n",
    "    refit='neg_mae',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid.fit(X_temp, y_temp)\n",
    "print(\"Best LGBM params:\", grid.best_params_)\n",
    "print(\"Best MAE:\", -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model_best = grid.best_estimator_\n",
    "\n",
    "lgb_model_best.fit(X_temp, y_temp)\n",
    "\n",
    "y_pred_lr_best = lgb_model_best.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_regression(y_test, y_pred_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ba0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(lgb_model_best, X_temp_df)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "print(\"SHAP summary plot:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(binary_features + numerical_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
