{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e55130a",
   "metadata": {},
   "source": [
    "# OS Status: classical ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d349de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# Importing necessary modules for preprocessing, model training, and evaluation\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Importing classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Importing metrics\n",
    "from sklearn.metrics import ( accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score, classification_report,\n",
    "                             confusion_matrix, roc_curve, precision_recall_curve)\n",
    "# For interpretability\n",
    "import shap\n",
    "\n",
    "# For reproducibility, the value is set for conventional reasons\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906aa682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('dataset_b.csv', encoding='latin-1', sep=',') # request the dataset to the author!\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0ed0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column : \"os_status\", binary variable\n",
    "# relevant columns\n",
    "relevant_columns = ['age', 'dcr', 'dnlr', 'histology', 'immuno_line', 'iorr', \n",
    "                    'ldhpre', 'leucotpre', 'nb_meta_beforeimmuno', 'neuttpre', \n",
    "                     'ps_befimmuno', 'sex', 'smoking_history', 'os_status']\n",
    "\n",
    "data = data[relevant_columns]\n",
    "data = data.dropna(axis=0)\n",
    "data['dcr'] = data['dcr'].astype(int)\n",
    "data['age'] = data['age'].astype(int)\n",
    "data['iorr'] = data['iorr'].astype(int)\n",
    "data['ps_befimmuno'] = data['ps_befimmuno'].astype(int)\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615ac015",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['histology'] = data['histology'].str.lower()\n",
    "data['sex'] = data['sex'].str.lower()\n",
    "data['smoking_history'] = data['smoking_history'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.dropna(axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e40e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to randomize the data\n",
    "data = data.sample(frac=1, random_state=SEED)\n",
    "\n",
    "# one-hot encoding\n",
    "one_hot_data = pd.get_dummies(data, columns=['histology', 'sex', 'smoking_history'])\n",
    "\n",
    "one_hot_data = one_hot_data.rename(columns={\n",
    "    'histology_Adenocarcinoma': 'histology_adenocarcinoma',\n",
    "    'histology_Squamous': 'histology_squamous',\n",
    "    'histology_Nsclc_other': 'histology_nsclc_other',\n",
    "    'histology_Large_cells': 'histology_large_cells',\n",
    "    'sex_Male': 'sex_male',\n",
    "    'sex_Female': 'sex_female',\n",
    "    'smoking_history_Non_smoker': 'smoking_history_non_smoker',\n",
    "    'smoking_history_Former': 'smoking_history_former',\n",
    "    'smoking_history_Current': 'smoking_history_current',\n",
    "    'smoking_history_Unk': 'smoking_history_unk'\n",
    "})\n",
    "\n",
    "#one_hot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace boolean values with 0 and 1\n",
    "for col in ['histology_adenocarcinoma','histology_squamous','histology_nsclc other',\n",
    "    'histology_large cells','sex_male','sex_female','smoking_history_non smoker','smoking_history_former','smoking_history_current',\n",
    "     'smoking_history_unk']:\n",
    "    one_hot_data[col] = one_hot_data[col].replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target\n",
    "X = one_hot_data[one_hot_data.columns.difference(['os_status'])]\n",
    "y = data['os_status']\n",
    "\n",
    "\n",
    "# First split: training+validation vs test (80% vs 20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify to maintain class distribution\n",
    ")\n",
    "\n",
    "# Second split: training vs validation (75% vs 25% of the remaining 80%)\n",
    "# This results in 60% training, 20% validation, and 20% test overall\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ensures that all numerical features contribute equally\n",
    "numerical_features = ['age', 'dcr', 'dnlr', 'ldhpre', 'leucotpre', \n",
    "                      'nb_meta_beforeimmuno', 'neuttpre', 'ps_befimmuno']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "binary_features = [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy() \n",
    "X_test_scaled = X_test.copy()\n",
    "X_scaled = X.copy()\n",
    "X_train_val_scaled = X_temp.copy()\n",
    "\n",
    "X_scaled[numerical_features] = scaler.fit_transform(X_scaled[numerical_features])\n",
    "X_train_scaled[numerical_features] = scaler.fit_transform(X_train_scaled[numerical_features])\n",
    "X_val_scaled[numerical_features] = scaler.transform(X_val_scaled[numerical_features])\n",
    "X_test_scaled[numerical_features] = scaler.transform(X_test_scaled[numerical_features])\n",
    "X_train_val_scaled[numerical_features] = scaler.fit_transform(X_train_val_scaled[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_proba, class_names=None):\n",
    "    \"\"\"\n",
    "    To evaluate a binary classification model.\n",
    "\n",
    "    Parameters:\n",
    "        y_true: array-like, real labels (0 o 1)\n",
    "        y_pred: array-like, predictive labels (0 o 1)\n",
    "        y_proba: array-like, probabilitys from the model (can be [n_samples] or [n_samples, 2])\n",
    "    \"\"\"\n",
    "\n",
    "    # If class names are not provided\n",
    "    if class_names is None:\n",
    "        class_names = ['Class 0', 'Class 1']\n",
    "\n",
    "    # If y_proba has 2 columns, take the probability of the positive class\n",
    "    if y_proba.ndim > 1 and y_proba.shape[1] == 2:\n",
    "        y_proba_pos = y_proba[:, 1]\n",
    "    else:\n",
    "        y_proba_pos = y_proba\n",
    "\n",
    "    # --- Global metrics ---\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "    # --- Complete Report ---\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- ROC Curve & PR Curve ---\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(y_true, y_proba_pos)\n",
    "        avg_precision = average_precision_score(y_true, y_proba_pos)\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(f\"Average Precision (PR AUC): {avg_precision:.4f}\")\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba_pos)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {auc_roc:.4f}\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "        # Precision-Recall curve\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_true, y_proba_pos)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(recall_vals, precision_vals, label=f\"AP = {avg_precision:.4f}\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(\"Precision-Recall Curve\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ROC/PR Curve Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3155e7",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f11107e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = binary_features + numerical_features\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "X_train_val_scaled_df = pd.DataFrame(X_train_val_scaled, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f024ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'neg_log_loss': 'neg_log_loss'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc18596",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2', None],  \n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'neg_log_loss': 'neg_log_loss'\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000, random_state=SEED),\n",
    "    param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_macro', \n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3dbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_best = grid.best_estimator_\n",
    "lr_model_best.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "#Predict the test set\n",
    "y_pred_lr_best = lr_model_best.predict(X_test_scaled)\n",
    "y_prob_lr_best = lr_model_best.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_model(y_test, y_pred_lr_best, y_prob_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(lr_model_best, X_train_val_scaled_df)\n",
    "shap_values = explainer(X_test_scaled_df)\n",
    "\n",
    "# Classe positiva (1)\n",
    "print(\"SHAP plot for class 1:\")\n",
    "shap.plots.beeswarm(shap_values, max_display=len(feature_names), show=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538f8a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],              \n",
    "    'max_depth': [None, 10, 20, 30],              \n",
    "    'class_weight': ['balanced', None],           \n",
    "    'bootstrap': [True, False],                   \n",
    "    'criterion': ['gini', 'entropy']              \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=SEED),\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_macro',    \n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_temp, y_temp)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_best = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred_rf_best = rf_model_best.predict(X_test)\n",
    "y_prob_rf_best = rf_model_best.predict_proba(X_test)\n",
    "evaluate_model(y_test, y_pred_rf_best, y_prob_rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6d88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_train_df = pd.DataFrame(X_temp, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e98708",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer= shap.TreeExplainer(rf_model_best, feature_perturbation=\"tree_path_dependent\")\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "shap.plots.beeswarm(shap_values[:,:,1], max_display=len(feature_names), show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510960ae",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],              \n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],       \n",
    "    'subsample': [0.6, 0.8, 1.0],                  \n",
    "    'max_features': ['sqrt', 'log2', None]         \n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='f1_macro',  \n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_temp, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f10894",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_best = grid_search.best_estimator_\n",
    "\n",
    "y_pred_gb_best = gb_model_best.predict(X_test)\n",
    "y_prob_gb_best = gb_model_best.predict_proba(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred_gb_best, y_prob_gb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48881d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_best.fit(X_train_val_scaled_df, y_temp)\n",
    "\n",
    "explainer = shap.Explainer(gb_model_best.predict_proba, X_train_val_scaled_df, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "shap.plots.beeswarm(shap_values[:,:,1], max_display=len(feature_names), show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de962a",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 1],\n",
    "\n",
    "}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  \n",
    "    random_state=42,\n",
    "    eval_metric='logloss',        \n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_macro', \n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_temp, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc66d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_xgb_best = best_xgb_model.predict(X_test)\n",
    "y_prob_xgb_best = best_xgb_model.predict_proba(X_test)\n",
    "evaluate_model(y_test, y_pred_xgb_best, y_prob_xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e541c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_xgb_model, X_train_df)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "shap.plots.beeswarm(shap_values, max_display=len(feature_names), show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf6101",
   "metadata": {},
   "source": [
    "# Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'max_depth': [-1, 10],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'min_child_samples': [1, 10],\n",
    "    'min_split_gain': [0.0, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'neg_log_loss': 'neg_log_loss'\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    random_state=42,\n",
    "    force_col_wise=True\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(lgbm, param_grid, cv=5, scoring=scoring,refit=\"f1_macro\" , n_jobs=-1, verbose=1)\n",
    "grid.fit(X_temp, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcff353",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbm_model = grid.best_estimator_\n",
    "\n",
    "y_pred_lgbm_best = best_lgbm_model.predict(X_test)\n",
    "y_prob_lgbm_best = best_lgbm_model.predict_proba(X_test)\n",
    "evaluate_model(y_test, y_pred_lgbm_best, y_prob_lgbm_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer= shap.TreeExplainer(best_lgbm_model, feature_perturbation=\"tree_path_dependent\")\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "shap.plots.beeswarm(shap_values, max_display=len(feature_names), show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54a70a",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6605840",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear', 'sigmoid'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'shrinking': [True, False] \n",
    "}\n",
    "\n",
    "\n",
    "svc = SVC(probability=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(svc, param_grid, cv=5, scoring=scoring,refit=\"f1_macro\" , n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc_model = grid.best_estimator_\n",
    "\n",
    "y_pred_svc_best = best_svc_model.predict(X_test)\n",
    "y_prob_svc_best = best_svc_model.predict_proba(X_test)\n",
    "evaluate_model(y_test, y_pred_svc_best, y_prob_svc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(best_svc_model.predict_proba, shap.kmeans(X_train_val_scaled_df, 10))\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100)\n",
    "\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values[:, :, 1],  \n",
    "    data=X_test_scaled_df,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap.plots.beeswarm(explanation, max_display=len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93257e5c",
   "metadata": {},
   "source": [
    "# K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [10, 12, 15, 17, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  \n",
    "    \n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='auto')\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring=scoring, refit=\"f1_macro\" , n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_model = grid.best_estimator_\n",
    "\n",
    "y_pred_knn_best = best_knn_model.predict(X_test)\n",
    "y_prob_knn_best = best_knn_model.predict_proba(X_test)\n",
    "evaluate_model(y_test, y_pred_knn_best, y_prob_knn_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac11b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = X_train_scaled_df.sample(50, random_state=42)\n",
    "explainer = shap.KernelExplainer(best_knn_model.predict_proba, background)\n",
    "X_subset = X_test_scaled_df[:20]  # taking a subset for faster computation\n",
    "shap_values = explainer.shap_values(X_subset)\n",
    "\n",
    "\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values[:, :, 1],  \n",
    "    data=X_subset,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "shap.plots.beeswarm(explanation, max_display=len(feature_names), show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfe52d",
   "metadata": {},
   "source": [
    "# Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 10, 100],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['auto','sag', 'lsqr', 'sparse_cg']\n",
    "    \n",
    "}\n",
    "scoring_rc = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro'\n",
    "}\n",
    "\n",
    "rc = RidgeClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(rc, param_grid, cv=5, scoring=scoring_rc, refit=\"f1_macro\" , n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train_val_scaled, y_temp)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rc_model = grid.best_estimator_\n",
    "\n",
    "y_pred_rc_best = best_rc_model.predict(X_test_scaled)\n",
    "y_prob_rc_best = best_rc_model.decision_function(X_test_scaled)\n",
    "evaluate_model(y_test, y_pred_rc_best, y_prob_rc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = shap.maskers.Independent(X_train_val_scaled_df)\n",
    "explainer = shap.LinearExplainer(best_rc_model, masker)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df)\n",
    "\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values,  \n",
    "    data=X_test_scaled_df,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap.plots.beeswarm(explanation, max_display=len(feature_names), show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906f4fb",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc115d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_val_scaled, y_temp)  \n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "y_prob_nb = nb_model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "evaluate_model(y_test, y_pred_nb, y_prob_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a251a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_val_scaled_df, 10)\n",
    "explainer = shap.KernelExplainer(nb_model.predict_proba, background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100)\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values[:, :, 1],  \n",
    "    data=X_test_scaled_df,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap.plots.beeswarm(explanation, max_display=len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd87bbd",
   "metadata": {},
   "source": [
    "# Decison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=tree,\n",
    "    param_grid=param_grid,\n",
    "    scoring= scoring, \n",
    "    refit=\"f1_macro\", \n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_temp, y_temp)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt_model = grid.best_estimator_\n",
    "\n",
    "y_pred_dt_best = best_dt_model.predict(X_test)\n",
    "y_prob_dt_best = best_dt_model.predict_proba(X_test)\n",
    "evaluate_model(y_test, y_pred_dt_best, y_prob_dt_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_dt_model, feature_perturbation=\"tree_path_dependent\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
