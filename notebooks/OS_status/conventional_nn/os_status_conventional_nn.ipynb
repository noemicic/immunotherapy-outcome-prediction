{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d1a23d",
   "metadata": {},
   "source": [
    "# OS Status: conventional NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a85dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#Importing modules for data preprocessing, model training\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "#Importing metrics for model evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "#Importing modules for building the neural network\n",
    "from tensorflow.keras import layers, regularizers\n",
    "#For model interpretation\n",
    "import shap\n",
    "\n",
    "\n",
    "# for reproducibility, the value is set for conventional reasons\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('dataset_b', encoding='latin-1', sep=',') # request the dataset to the author\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9150b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column : \"os_status\", binary variable\n",
    "# relevant columns\n",
    "relevant_columns = ['age', 'dcr', 'dnlr', 'histology', 'immuno_line', 'iorr', \n",
    "                    'ldhpre', 'leucotpre', 'nb_meta_beforeimmuno', 'neuttpre', \n",
    "                     'ps_befimmuno', 'sex', 'smoking_history', 'os_status']\n",
    "\n",
    "data = data[relevant_columns]\n",
    "data = data.dropna(axis=0)\n",
    "data['dcr'] = data['dcr'].astype(int)\n",
    "data['age'] = data['age'].astype(int)\n",
    "data['iorr'] = data['iorr'].astype(int)\n",
    "data['ps_befimmuno'] = data['ps_befimmuno'].astype(int)\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c7d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['histology'] = data['histology'].str.lower()\n",
    "data['sex'] = data['sex'].str.lower()\n",
    "data['smoking_history'] = data['smoking_history'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4a0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to randomize the data\n",
    "data = data.sample(frac=1, random_state=SEED)\n",
    "\n",
    "# one-hot encoding\n",
    "one_hot_data = pd.get_dummies(data, columns=['histology', 'sex', 'smoking_history'])\n",
    "\n",
    "one_hot_data = one_hot_data.rename(columns={\n",
    "    'histology_Adenocarcinoma': 'histology_adenocarcinoma',\n",
    "    'histology_Squamous': 'histology_squamous',\n",
    "    'histology_Nsclc_other': 'histology_nsclc_other',\n",
    "    'histology_Large_cells': 'histology_large_cells',\n",
    "    'sex_Male': 'sex_male',\n",
    "    'sex_Female': 'sex_female',\n",
    "    'smoking_history_Non_smoker': 'smoking_history_non_smoker',\n",
    "    'smoking_history_Former': 'smoking_history_former',\n",
    "    'smoking_history_Current': 'smoking_history_current',\n",
    "    'smoking_history_Unk': 'smoking_history_unk'\n",
    "})\n",
    "\n",
    "#one_hot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace boolean values with 0 and 1\n",
    "for col in ['histology_adenocarcinoma','histology_squamous','histology_nsclc other',\n",
    "    'histology_large cells','sex_male','sex_female','smoking_history_non smoker','smoking_history_former','smoking_history_current',\n",
    "     'smoking_history_unk']:\n",
    "    one_hot_data[col] = one_hot_data[col].replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e07200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target\n",
    "X = one_hot_data[one_hot_data.columns.difference(['os_status'])]\n",
    "y = data['os_status']\n",
    "\n",
    "\n",
    "# First split: training+validation vs test (80% vs 20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify to maintain class distribution\n",
    ")\n",
    "\n",
    "# Second split: training vs validation (75% vs 25% del 80%)\n",
    "# This results in 60% train, 20% val, 20% test\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ensures that all numerical features contribute equally\n",
    "numerical_features = ['age', 'dcr', 'dnlr', 'ldhpre', 'leucotpre', \n",
    "                      'nb_meta_beforeimmuno', 'neuttpre', 'ps_befimmuno']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "binary_features = [col for col in X.columns if col not in numerical_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy() \n",
    "X_test_scaled = X_test.copy()\n",
    "X_scaled = X.copy()\n",
    "\n",
    "\n",
    "X_scaled[numerical_features] = scaler.fit_transform(X_scaled[numerical_features])\n",
    "X_train_scaled[numerical_features] = scaler.fit_transform(X_train_scaled[numerical_features])\n",
    "X_val_scaled[numerical_features] = scaler.transform(X_val_scaled[numerical_features])\n",
    "X_test_scaled[numerical_features] = scaler.transform(X_test_scaled[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766cdf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4905e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X.copy()\n",
    "X_scaled[numerical_features] = scaler.fit_transform(X_scaled[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eff60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons, L2 regularization 0.01 and increased dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "126f74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons, Norm Layer, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66eb402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9411409",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44861b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons, Batch layer, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=500, batch_size=16)\n",
    "\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6f3c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 2 hidden layers, each of them with 512 neurons, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6235d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a81356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 2 hidden layers, each of them with 512 neurons,Norm layer, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)), \n",
    "    layers.LayerNormalization(center=True, scale=True),\n",
    "    layers.Dropout(0.4),  \n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d919db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 2 hidden layers, each of them with 512 neurons, Norm layer, ElasticNet and  dropout 0.2\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01)), \n",
    "    layers.LayerNormalization(center=True, scale=True),\n",
    "    layers.Dropout(0.2),  \n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4b769cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "\n",
    "# Convert the probabilities into binary predictions\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69111135",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions)\n",
    "recall = recall_score(y_test, class_predictions)\n",
    "f1 = f1_score(y_test, class_predictions)\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)  \n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "prob_predictions = np.squeeze(prob_predictions)\n",
    "class_predictions = (prob_predictions >= 0.5).astype(int)\n",
    "data['Predicted'] = class_predictions\n",
    "\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "\n",
    "X_subset = X_test_scaled_df.sample(50, random_state=42)\n",
    "shap_values = explainer.shap_values(X_subset, nsamples=50, silent=True)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}, X_subset shape: {X_subset.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    features=X_subset,\n",
    "    feature_names=X_subset.columns,\n",
    "    plot_type='dot',\n",
    "    max_display=len(binary_features + numerical_features),\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot – Class 1\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_binary.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
