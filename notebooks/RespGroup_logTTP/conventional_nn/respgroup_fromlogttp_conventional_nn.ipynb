{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d1a23d",
   "metadata": {},
   "source": [
    "# RespGroup_logTTP: conventional NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#Importing to preprocess the data\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "from sklearn.preprocessing import label_binarize\n",
    "#Importing to build the models\n",
    "from tensorflow.keras import layers, regularizers, models\n",
    "#Importing to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "#Importing to explain the models\n",
    "import shap\n",
    "\n",
    "# for reproducibility, the value is set for conventional reasons\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('dataset_d.csv', encoding='latin-1', sep=',') #request the dataset to the author\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column : \"progression_log_cat\" multi-classification problem\n",
    "# relevant columns for the model\n",
    "relevant_columns = [ 'age', 'sex', 'smoking', 'ps_at_diagnosis_ad', 'n#_mets_sites', 'lung_only_m1', 'pleural', 'pericard','lymph_nodes_only_m1','soft_tissue',\n",
    "    'leptomingeal','skin','peritoneal','renal','pancreas', 'brain', 'liver', 'bone', 'adrenal', 'histology', 'hbbaselineio','leucotbaselineio',\n",
    "    'neut_abs...143','linfo_abs...144','baso_abs...145', 'mono_abs...147', 'plaqtbaselineio', 'progression_log_cat']\n",
    "df= data.copy()\n",
    "df = df[relevant_columns]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d62b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17827da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to randomize the data\n",
    "df = df.sample(frac=1, random_state=SEED)\n",
    "\n",
    "var_int = ['ps_at_diagnosis_ad', 'n#_mets_sites', 'lung_only_m1', 'pleural', 'pericard', 'lymph_nodes_only_m1', 'soft_tissue',\n",
    "           'leptomingeal','skin','peritoneal','renal','pancreas', 'brain', 'liver', 'bone', 'adrenal']\n",
    "for i in var_int:\n",
    "    df[i] = df[i].astype(int)\n",
    "    \n",
    "df['sex'] = df['sex'].str.lower()\n",
    "\n",
    "sex_dummies = pd.get_dummies(df['sex'], prefix='sex', drop_first=True)\n",
    "\n",
    "other_dummies = pd.get_dummies(df[['histology', 'smoking']])\n",
    "\n",
    "df_encoded = pd.concat([df.drop(columns=['sex', 'histology', 'smoking']),\n",
    "                        sex_dummies, other_dummies], axis=1)\n",
    "\n",
    "cols_to_convert = ['histology_adenocarcinoma', 'histology_nsclc', 'histology_squamous' ,'sex_male', \n",
    "                   'smoking_current', 'smoking_former', 'smoking_non-smoker'] #,'histology_adenosquamous'\n",
    "\n",
    "df_encoded[cols_to_convert] = df_encoded[cols_to_convert].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e170ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target\n",
    "X = df_encoded[df_encoded.columns.difference(['progression_cat'])]  # Exclude the target column\n",
    "y = df_encoded['progression_cat']  \n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68013f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train_val:\",X_train_val.shape)\n",
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of X_val:\",X_val.shape)\n",
    "print(\"Shape of X_test:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features = ['lung_only_m1', 'pleural', 'pericard', 'lymph_nodes_only_m1', 'soft_tissue', 'leptomingeal','skin','peritoneal','renal',\n",
    "                   'pancreas', 'brain', 'liver', 'bone', 'adrenal','histology_adenocarcinoma', 'histology_nsclc', \n",
    "                   'histology_squamous', 'sex_male','smoking_current', 'smoking_former', 'smoking_non-smoker' ]#'histology_adenosquamous',\n",
    "numeric_features = ['neut_abs...143','linfo_abs...144', 'plaqtbaselineio', 'age', 'ps_at_diagnosis_ad', 'n#_mets_sites', 'leucotbaselineio',\n",
    "                    'hbbaselineio','baso_abs...145', 'mono_abs...147'] #'duration_l1', 'time_to_l1_start'\n",
    "\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy() \n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_val_scaled = X_train_val.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_val_scaled[numeric_features] = scaler.fit_transform(X_train_val_scaled[numeric_features])\n",
    "X_train_scaled[numeric_features] = scaler.fit_transform(X_train_scaled[numeric_features])\n",
    "X_val_scaled[numeric_features] = scaler.fit_transform(X_val_scaled[numeric_features])\n",
    "X_test_scaled[numeric_features] = scaler.fit_transform(X_test_scaled[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, label in enumerate(le.classes_):\n",
    "    print(f\"{idx}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4905e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X.copy()\n",
    "X_scaled[numeric_features] = scaler.fit_transform(X_scaled[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_val_scaled_df = pd.DataFrame(X_train_val_scaled, columns=X_train_val.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2317f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=X_test_scaled_df.columns,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07414620",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=X_test_scaled_df.columns,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons, Norm layer, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b219a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=X_test_scaled_df.columns,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False  \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 1 hidden layer with 512 neurons, Batch layer, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f23229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efce2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=X_test_scaled_df.columns,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False  \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 2 hidden layers, each of them with 512 neurons, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1052e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=X_test_scaled_df.columns,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False  \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a81356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 2 hidden layers, each of them with 512 neurons, Norm layer, L2 regularization 0.01 and dropout 0.4\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l2(0.01)), \n",
    "    layers.LayerNormalization(center=True, scale=True),\n",
    "    layers.Dropout(0.4),  \n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51164610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7835d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=X_test_scaled_df.columns,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False  \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 2 hidden layers, each of them with 512 neurons, Norm layer, ElasticNet and dropout 0.2\n",
    "mlp_model = tf.keras.models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01)), \n",
    "    layers.LayerNormalization(center=True, scale=True),\n",
    "    layers.Dropout(0.2),  \n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train_scaled, y_train,\n",
    "                         validation_data=(X_val_scaled, y_val),\n",
    "                         epochs=500, batch_size=16)\n",
    "\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot of the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'b', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot of accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9737307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Get the predicted class index\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "\n",
    "original_predictions = le.inverse_transform(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, class_predictions)\n",
    "precision = precision_score(y_test, class_predictions, average='weighted')\n",
    "recall = recall_score(y_test, class_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, class_predictions, average='weighted')\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "roc_auc = roc_auc_score(y_test_bin, prob_predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "print(classification_report(y_test, class_predictions))\n",
    "print(confusion_matrix(y_test, class_predictions))\n",
    "\n",
    "prob_predictions = mlp_model.predict(X_scaled)\n",
    "class_predictions = np.argmax(prob_predictions, axis=1)\n",
    "original_predictions = le.inverse_transform(class_predictions)\n",
    "df['Predicted'] = original_predictions\n",
    "\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd52e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.kmeans(X_train_scaled, 10)\n",
    "explainer = shap.KernelExplainer(lambda x: mlp_model.predict(x), background)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df, nsamples=100, silent=True)\n",
    "\n",
    "class_names = le.classes_  \n",
    "for i, class_name in enumerate(class_names):\n",
    "    shap.summary_plot(\n",
    "        shap_values[:,:,i], \n",
    "        features=X_test_scaled_df,\n",
    "        feature_names=binary_features + numeric_features,\n",
    "        plot_type='dot',\n",
    "        max_display=len(binary_features + numeric_features),\n",
    "        show=False  \n",
    "    )\n",
    "    plt.title(f\"Class {class_name}\")\n",
    "    plt.savefig(f\"shap_plot_class_{class_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    img = plt.imread(f\"shap_plot_class_{class_name}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"Class {class_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
